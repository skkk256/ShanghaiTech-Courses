{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet50(pretrained=False, num_classes=10)\n",
    "\n",
    "test_tensor = torch.randn(4, 3, 32, 32)\n",
    "print(net(test_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(net, optimizer, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.train(epochs=40, data_loader=trainloader, log=True, save_per_epoch=10, val_loader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.test(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_resnet = nn.Sequential(*list(net.children())[:-1])\n",
    "\n",
    "# 添加新的全连接层\n",
    "num_classes = 10\n",
    "projection =  nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256), \n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10),\n",
    ")\n",
    "\n",
    "net_with_projection = nn.Sequential(\n",
    "    pretrained_resnet,\n",
    "    projection\n",
    ")\n",
    "# for param in pretrained_resnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "net_with_projection.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_with_projection.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(net_with_projection, optimizer, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "log = True\n",
    "solver.train(epoch, trainloader, log,  save_per_epoch=5, val_loader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.load_checkpoints(\"/data/shengkuan/CS172/cs172-assignment1-2023fall-skkk256/checkpoints/resnet34_fintune4_replace.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ResNet import resnet50\n",
    "\n",
    "# Untrained model\n",
    "my_model = resnet50()\n",
    "\n",
    "# Pretrained model\n",
    "my_model = resnet50(pretrained=True, checkpoints_path=\"/data/shengkuan/CS172/cs172-assignment1-2023fall-skkk256/checkpoints/resnet50.pt\")\n",
    "my_model.eval() # for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(my_model, optimizer, criterion, device=device)\n",
    "solver.test(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from modules.dataloader import SHHA_loader\n",
    "from modules.crowd_counting import data_collate, draw_and_save\n",
    "from modules.utils import get_density_map_gaussian\n",
    "from modules.ResNet import MCNN\n",
    "from modules.ResNet import UNet, resnet50\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/shengkuan/CS172/cs172-assignment1-2023fall-skkk256/data/ShanghaiTech_Crowd_Counting_Dataset/part_B_final\"\n",
    "output_size = 512\n",
    "num_workers = 4\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = SHHA_loader(data_path, \"train\", output_size)\n",
    "test_dataset = SHHA_loader(data_path, \"test\", output_size)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size, True,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=True, collate_fn=data_collate)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size, False,\n",
    "    num_workers=num_workers, pin_memory=True, drop_last=False, collate_fn=data_collate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "image, gt = next(dataiter)\n",
    "print(image[0].min(), image[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "fg, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(test_loader)\n",
    "for inputs in dataiter:\n",
    "    images, gt = inputs\n",
    "    # # show images\n",
    "    # imshow(torchvision.utils.make_grid(images))\n",
    "    # print(gt[0].shape)\n",
    "    # # print labels\n",
    "    # # print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "    # draw_and_save(images, gt, \"/data/shengkuan/CS172/cs172-assignment1-2023fall-skkk256/output\", 0)\n",
    "    density_maps = []\n",
    "    for i in range(len(images)):\n",
    "        density_map = get_density_map_gaussian(images[i][0], gt[i].numpy())\n",
    "        density_map = cv2.resize(density_map,(128, 128))\n",
    "        density_maps.append(density_map)\n",
    "        \n",
    "    ax0.imshow(np.transpose(images[0], (1, 2, 0)))\n",
    "    ax0.set_title(str(gt[0].shape[0]))\n",
    "    ax1.imshow(density_maps[0], cmap=plt.cm.jet)\n",
    "    ax1.set_title(str(np.sum(density_maps[0]) * 16))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1WithFactor(nn.Module):\n",
    "    def __init__(self, factor):\n",
    "        super(L1WithFactor, self).__init__()\n",
    "        self.factor = factor\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        mse = nn.functional.l1_loss(input, target)\n",
    "        loss = mse * self.factor\n",
    "        return loss\n",
    "factor = 100\n",
    "loss_fn = L1WithFactor(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MCNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.crowd_counting import Task2_Solver\n",
    "\n",
    "task2_solver = Task2_Solver(model, optimizer, criterion, model_name=\"MCNN_B\", downsample=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_solver.load_checkpoints(\"/data/shengkuan/CS172/cs172-assignment1-2023fall-skkk256/checkpoints/MCNN_10-29_15-48-42_160.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 160\n",
    "save_per_epoch = 20\n",
    "log = True\n",
    "\n",
    "task2_solver.train(epoch, train_loader, log, save_per_epoch=save_per_epoch, val_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_solver.test(test_loader, 10, \"10-24_20-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(54.9886, device='cuda:2') tensor(163.2789, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "mae, mse = task2_solver.evaluate_model(test_loader)\n",
    "print(mae, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mae.cpu(), mse.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_solver(images.to(device))/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "dataiter = next(dataiter)\n",
    "images, gt = dataiter\n",
    "\n",
    "task2_solver.load_checkpoints(\"/data/shengkuan/CS172/cs172-assignment1-2023fall-skkk256/checkpoints/MCNN_10-29_15-48-42_160.pth\")\n",
    "# task2_solver(images.to(device))\n",
    "task2_solver.test(train_loader, \"test-B\", \"10-29_18-56\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
