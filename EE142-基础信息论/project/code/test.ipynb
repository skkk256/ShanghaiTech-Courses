{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/infodp/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/root/anaconda3/envs/infodp/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import torch as t\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from daam import trace\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import utils\n",
    "from utils.itdiffusion import DiffusionModel  # Info theoretic diffusion library and flow sampler\n",
    "from utils.stablediffusion import StableDiffuser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess lora weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from safetensors.torch import load_file, save_file\n",
    "\n",
    "# model_file = load_file(\"/root/tmp/EE142/model/Burberry.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dict = {}\n",
    "\n",
    "# for k, v in model_file.items():\n",
    "#     if \"unet\" in k:\n",
    "#         # if \"down\" in k:\n",
    "#         #     if v.shape == t.Size([128, 320, 1, 1]):\n",
    "#         #         v = v.reshape(128, 320)\n",
    "#         #         # print(k, v.shape)\n",
    "#         #     elif v.shape == t.Size([128, 640, 1, 1]):\n",
    "#         #         v = v.reshape(128, 640)\n",
    "#         #     elif v.shape == t.Size([128, 1280, 1, 1]):\n",
    "#         #         v = v.reshape(128, 1280)\n",
    "#         #         # print(k, v.shape)\n",
    "\n",
    "#         # if \"up\" in k:\n",
    "#         #     if v.shape == t.Size([320, 128, 1, 1]):\n",
    "#         #         v = v.reshape(320, 128)\n",
    "#         #         # print(k, v.shape)\n",
    "#         #     elif v.shape == t.Size([640, 128, 1, 1]):\n",
    "#         #         v = v.reshape(640, 128)\n",
    "#         #     elif v.shape == t.Size([1280, 128, 1, 1]):\n",
    "#         #         v = v.reshape(1280, 128)\n",
    "#         #         # print(k, v.shape)\n",
    "\n",
    "#         new_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_file(new_dict, \"/root/tmp/EE142/model/Burberry_unet.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper-parameters\n",
    "seed = 42\n",
    "data_in_dir = \"/root/tmp/EE142/data/coco/val2017\"\n",
    "res_out_dir = \"/root/tmp/EE142/data/results/test\"\n",
    "n_samples_per_point = 120\n",
    "batch_size = 120\n",
    "num_steps = 100\n",
    "sdm_version = 'sdm_2_0_base' \n",
    "clip = 3\n",
    "\n",
    "t.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f31f144d3d24530862d473f4e7fdcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load diffusion models\n",
    "if sdm_version == 'sdm_2_0_base':\n",
    "    sdm = StableDiffuser(\"/root/tmp/EE142/model/models--stabilityai--stable-diffusion-2-base/snapshots/fa386bb446685d8ad8a8f06e732a66ad10be6f47\")\n",
    "elif sdm_version == 'sdm_2_1_base':\n",
    "    sdm = StableDiffuser(\"stabilityai/stable-diffusion-2-1-base\")\n",
    "\n",
    "logsnr_max, logsnr_min = sdm.logsnr_max, sdm.logsnr_min\n",
    "logsnr_loc = logsnr_min + 0.5 * (logsnr_max - logsnr_min)\n",
    "logsnr_scale = (1. / (2. * clip)) * (logsnr_max - logsnr_min)\n",
    "\n",
    "latent_shape = (sdm.channels, sdm.width, sdm.height)\n",
    "itd = DiffusionModel(sdm.unet, latent_shape, logsnr_loc=logsnr_loc, logsnr_scale=logsnr_scale, clip=clip,\n",
    "                        logsnr2t=sdm.logsnr2t).to(sdm.device)\n",
    "\n",
    "# Defines range of sigma/snr to use during sampling, based on training\n",
    "\n",
    "sigma_min, sigma_max = utils.logsnr2sigma(logsnr_max), utils.logsnr2sigma(logsnr_min)\n",
    "\n",
    "# Set schedule in Karras et al terms, \"sigmas\", where z = x + sigma epsilon.\n",
    "schedule = utils.get_sigmas_karras(num_steps, sigma_min, sigma_max, device=itd.device)\n",
    "# For generation, use schedule. For reversible sampling use the following, which\n",
    "# doesn't go all the way to the limit sigma=0, snr=inf We can't approx score there so can't reverse\n",
    "schedule_reversible = schedule[:-1]\n",
    "\n",
    "# Step function for ODE flow. Choose second order \"Heun\" solver, s_churn = 0. gives deterministic\n",
    "step_function = utils.get_step(order=2, s_churn=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = [\n",
    "    (\"dog\", \"cat\"),\n",
    "    (\"zebra\", \"horse\"),\n",
    "    (\"bed\", \"table\"),\n",
    "    (\"bear\", \"elephant\"),\n",
    "    (\"airplane\", \"kite\"),\n",
    "    (\"person\", \"monkey\"),\n",
    "    (\"people\", \"monkeys\"),\n",
    "    (\"teddy bear\", \"robot\"),\n",
    "    (\"three\", \"no\"),\n",
    "    (\"five\", \"no\"),\n",
    "]\n",
    "word_swaps = {}  # Create an empty dictionary for word swaps\n",
    "for a, b in word_pairs:\n",
    "    word_swaps[a] = b\n",
    "    word_swaps[b] = a\n",
    "    word_swaps[a + 's'] = b + 's'\n",
    "    word_swaps[b + 's'] = a + 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change the data pipeline\n",
    "# df = pd.read_csv('/root/tmp/EE142/data/coco/COCO-IT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# row = {\n",
    "#     # 'Image ID': 397133,\n",
    "#     \"image_path\": \"/root/tmp/EE142/data/sk_test/five_bowls.png\",\n",
    "#     'Label': 'five',\n",
    "#     'correct_obj+context': 'there are three bowls on the ground',\n",
    "#     'context': 'there are bowls on the ground',\n",
    "#     'correct_obj': 'three'\n",
    "# }\n",
    "\n",
    "# row = {\n",
    "#     # 'Image ID': 397133,\n",
    "#     \"image_path\": \"/root/tmp/EE142/data/coco/val2017/000000577149.jpg\",\n",
    "#     'Label': 'zebras',\n",
    "#     'correct_obj+context': 'there are four zebras walking on the side of this road',\n",
    "#     'context': 'there are fout walking on the side of this road',\n",
    "#     'correct_obj': 'zebras'\n",
    "# }\n",
    "\n",
    "# row = {\n",
    "#     # 'Image ID': 397133,\n",
    "#     \"image_path\": \"/root/tmp/EE142/data/sk_test/Snipaste_2024-12-31_20-05-04.png\",\n",
    "#     'Label': 'monkey',\n",
    "#     'correct_obj+context': 'The monkey with the hat is sitting on the ground',\n",
    "#     'context': 'The monkey with the hat is sitting on the ground',\n",
    "#     'correct_obj': 'monkey'\n",
    "# }\n",
    "\n",
    "row = {\n",
    "    # 'Image ID': 397133,\n",
    "    \"image_path\": \"/root/tmp/EE142/data/coco/val2017/000000001296.jpg\",\n",
    "    'Label': 'lora',\n",
    "    'correct_obj+context': 'figure of ',\n",
    "    'context': 'The monkey with the hat is sitting on the ground',\n",
    "    'correct_obj': 'monkey'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_name = f\"{row['Image ID']:012d}.jpg\"\n",
    "\n",
    "# path = os.path.join(data_in_dir, img_name)\n",
    "path = row[\"image_path\"]\n",
    "\n",
    "img = Image.open(path).convert('RGB')\n",
    "object, prompt = row['correct_obj'], row['correct_obj+context']\n",
    "print(f\"Processing {path} with object: {object} and prompt: {prompt}\")\n",
    "\n",
    "mod_prompt = utils.perform_word_swaps(prompt, {object: '_', object + 's': '_'})\n",
    "word_swap = word_swaps.get(object, object)\n",
    "swap_prompt = utils.perform_word_swaps(prompt, word_swaps)\n",
    "\n",
    "print(f\"\"\"\n",
    "    Original prompt: {prompt}\n",
    "    Modified prompt: {mod_prompt}\n",
    "    Word swap prompt: {swap_prompt}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode image to SD latent space\n",
    "x_real_transformed = sdm.sdm_pipe.image_processor.preprocess(img, height=512, width=512).squeeze().permute((1, 2, 0))\n",
    "x_real = sdm.encode_latents(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_real_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_decoded = sdm.decode_latents(x_real)[0]\n",
    "img_decoded\n",
    "# img_numpy = img_decoded.sample.cpu().detach().numpy().squeeze().transpose(1, 2, 0)\n",
    "# img_numpy = np.clip(img_numpy, 0, 1)\n",
    "\n",
    "# Image.fromarray((img_numpy * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode prompts to CLIP embedding space\n",
    "\n",
    "mod_prompt = \"there are four _ walking on the side of this road\"\n",
    "\n",
    "\n",
    "print(f\"\"\"prompt = {prompt}\n",
    "object = {object}\n",
    "mod_prompt = {mod_prompt}\n",
    "swap_prompt = {swap_prompt}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "v_org = sdm.encode_prompts(prompt).expand(batch_size, -1, -1)\n",
    "v_null = sdm.encode_prompts('').expand(batch_size, -1, -1)\n",
    "v_obj = sdm.encode_prompts(object).expand(batch_size, -1, -1)\n",
    "v_mod = sdm.encode_prompts(mod_prompt).expand(batch_size, -1, -1)\n",
    "v_swap = sdm.encode_prompts(swap_prompt).expand(batch_size, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in reverse to get the latent\n",
    "latent_real = utils.reverse(sdm, step_function, schedule_reversible, x_real, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_decoded = sdm.decode_latents(latent_real)[0]\n",
    "img_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################################\n",
    "# ##                   No intervention                ##\n",
    "# ######################################################\n",
    "# # Then run forward (no intervention) and check recovery of real image - also track attention\n",
    "# with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "#     with trace(sdm.sdm_pipe) as tc:\n",
    "#         recover_real = utils.generate(sdm, step_function, schedule_reversible, latent_real, prompt)\n",
    "\n",
    "# # Recover heat map\n",
    "# heat_map = tc.compute_global_heat_map(prompt)\n",
    "# heat_map = heat_map.compute_word_heat_map(object)  # keyword\n",
    "# heat_map_lr = heat_map.value\n",
    "# heat_map = F.interpolate(heat_map.value.unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "# # Decode real image without intervention\n",
    "# recover_real_decode = sdm.decode_latents(recover_real)[0]\n",
    "# recover_real_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(heat_map.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "##              Omit & Swap intervention            ##\n",
    "######################################################\n",
    "# Then run with a change in the prompt\n",
    "print(f\"Running with prompt: {mod_prompt}\")\n",
    "recover_mod = utils.generate(sdm, step_function, schedule_reversible, latent_real, mod_prompt)\n",
    "recover_mod_decode = sdm.decode_latents(recover_mod)[0]\n",
    "\n",
    "recover_mod_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same, but swap a word instead\n",
    "print(f\"Running with prompt: {swap_prompt}\")\n",
    "recover_swap = utils.generate(sdm, step_function, schedule_reversible, latent_real, swap_prompt)\n",
    "recover_swap_decode = sdm.decode_latents(recover_swap)[0]\n",
    "\n",
    "recover_swap_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "\n",
    "gc.collect()\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pixel_nll\n",
    "with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "    pixel_nll, pixel_mi_appx = itd.image_level_nll(x_real, v_org, 20, bs_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Info heat maps\n",
    "with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "    results_dict = itd.ll_ratio(x_real, v_null, v_obj, n_points=20,\n",
    "                                n_samples_per_point=n_samples_per_point,\n",
    "                                batch_size=batch_size, dim=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_pixel_lr = results_dict['ll_ratio_pixel_app']\n",
    "mi_pixel = F.interpolate(results_dict['ll_ratio_pixel_app'].unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "mi = results_dict['ll_ratio_pixel_app'].sum()\n",
    "\n",
    "plt.imshow(mi_pixel.cpu().detach().numpy());\n",
    "print(f\"MI: {mi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"there are four zebras walking on the side of this road\"\n",
    "\n",
    "word_list = [\"four\", \"zebras\", \"walking\", \"road\"]\n",
    "results_list = []\n",
    "\n",
    "for word in word_list:\n",
    "    mod_prompt = prompt.replace(word, \"_\")\n",
    "    print(f\"Running with prompt: {mod_prompt}\")\n",
    "\n",
    "    v_mod = sdm.encode_prompts(mod_prompt).expand(batch_size, -1, -1)\n",
    "\n",
    "    with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "        results_dict = itd.ll_ratio(x_real, v_mod, v_org, n_points=20,\n",
    "                                    n_samples_per_point=n_samples_per_point,\n",
    "                                    batch_size=batch_size, dim=(1,))\n",
    "    cmi_pixel_lr = results_dict['ll_ratio_pixel_app']\n",
    "    cmi_pixel = F.interpolate(results_dict['ll_ratio_pixel_app'].unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "    cmi = results_dict['ll_ratio_pixel'].sum()\n",
    "\n",
    "    results_list.append(results_dict)\n",
    "\n",
    "    # plt.imshow(cmi_pixel.cpu().detach().numpy());\n",
    "    print(f\"CMI: {cmi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/tmp/EE142/Info-Decomp')\n",
    "from scripts.visual import *\n",
    "\n",
    "# x_real_transformed = results_dict['x_real_transformed'].cpu()\n",
    "thresh = 0.1\n",
    "\n",
    "fig1, axs1 = plt.subplots(1, 1 + len(results_list), figsize=(3 * (1 + len(results_list)), 3))\n",
    "\n",
    "plot_img(x_real_transformed, axs1[0], title='Real COCO image')\n",
    "\n",
    "for i in range(len(results_list)):\n",
    "    cmi_pixel_lr = results_list[i]['ll_ratio_pixel_app']\n",
    "    cmi_pixel = F.interpolate(results_list[i]['ll_ratio_pixel_app'].unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "    cmi = results_list[i]['ll_ratio_pixel'].sum()\n",
    "\n",
    "    plot_overlay(x_real_transformed, cmi_pixel, fig1, axs1[i+1], title=word_list[i] + ' $\\mathfrak{i}(x;y|c)$',\n",
    "                    normalize=False,\n",
    "                    vmax=thresh, inset_text=cmi)\n",
    "    \n",
    "fig1.savefig(\"/root/tmp/EE142/data/sk_output/word/result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "    results_dict = itd.ll_ratio(x_real, v_swap, v_org, n_points=20,\n",
    "                                n_samples_per_point=n_samples_per_point,\n",
    "                                batch_size=batch_size, dim=(1,))\n",
    "cmi_pixel_swap_lr = results_dict['ll_ratio_pixel_app']\n",
    "cmi_pixel_swap = F.interpolate(results_dict['ll_ratio_pixel_app'].unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "cmi_swap = results_dict['ll_ratio_pixel'].sum()\n",
    "\n",
    "plt.imshow(cmi_pixel_swap.cpu().detach().numpy());\n",
    "print(f\"CMI SWAP: {cmi_swap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(path).convert('RGB')\n",
    "object, prompt = row['correct_obj'], row['correct_obj+context']\n",
    "print(f\"Processing {path} with object: {object} and prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_images = sdm.encode_latents(img)\n",
    "text_embeddings = sdm.encode_prompts(\"there are five bowls on the ground\")\n",
    "wro_embeddings = sdm.encode_prompts(\"there are three bowls on the ground\")\n",
    "uncond_embeddings = sdm.encode_prompts(\"\")\n",
    "conds = t.stack([text_embeddings, wro_embeddings, uncond_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsnrs = t.linspace(1.0 - 3.0 * 2.0, 1.0 + 3.0 * 2.0, 100).to(sdm.device)\n",
    "z_sample_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmses, mmses_diff_appx = itd.image_level_mmse(latent_images, conds, logsnrs, total=z_sample_num, bs_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmses_diff_appx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_mmses, pixel_mmses_diff_appx = itd.pixel_level_mmse(latent_images, conds, logsnrs, total=z_sample_num, bs_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_mmses_up = t.zeros(list(pixel_mmses.shape[:-2]) + [512, 512])\n",
    "pixel_mmses_diff_appx_up = t.zeros(list(pixel_mmses_diff_appx.shape[:-2]) + [512, 512])\n",
    "for i in range(100):\n",
    "    pixel_mmses_up[i] = F.interpolate(pixel_mmses[i], size=(512, 512), mode=\"bilinear\")\n",
    "    pixel_mmses_diff_appx_up[i] = F.interpolate(pixel_mmses_diff_appx[i], size=(512, 512), mode=\"bilinear\")\n",
    "pixel_mmses_up = pixel_mmses_up.permute(2, 1, 0, 3, 4)  # bs * 3 * snr_num * h * w\n",
    "pixel_mmses_diff_appx_up = pixel_mmses_diff_appx_up.permute(2, 1, 0, 3, 4)  # bs * 3 * snr_num * h * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pixel_mmses_up[0][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_save = {\n",
    "#     'mod_prompt': mod_prompt,\n",
    "#     'object': object,\n",
    "#     'word_swap': word_swap,\n",
    "#     'x_real_transformed': x_real_transformed,\n",
    "#     'recover_real_decode': recover_real_decode,\n",
    "#     'recover_mod_decode': recover_mod_decode,\n",
    "#     'recover_swap_decode': recover_swap_decode,\n",
    "#     'recover_mod': recover_mod,\n",
    "#     'recover_swap': recover_swap,\n",
    "#     'recover_real': recover_real,\n",
    "#     'cmi_pixel': cmi_pixel,\n",
    "#     'cmi_pixel_swap': cmi_pixel_swap,\n",
    "#     'mi_pixel': mi_pixel,\n",
    "#     'cmi_pixel_lr': cmi_pixel_lr,\n",
    "#     'cmi_pixel_swap_lr': cmi_pixel_swap_lr,\n",
    "#     'mi_pixel_lr': mi_pixel_lr,\n",
    "#     'heat_map_lr': heat_map_lr,\n",
    "#     'heat_map': heat_map,\n",
    "#     'cmi': cmi,\n",
    "#     'cmi_swap': cmi_swap,\n",
    "#     'mi': mi\n",
    "# }\n",
    "\n",
    "# # Save the dictionary to a file\n",
    "# if not os.path.exists(res_out_dir):\n",
    "#     os.makedirs(res_out_dir)\n",
    "# t.save(data_to_save, os.path.join(res_out_dir, img_name[:-4] + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in df.iterrows():\n",
    "#     img_name = f\"{row['Image ID']:012d}.jpg\"\n",
    "#     path = os.path.join(data_in_dir, img_name)\n",
    "#     img = Image.open(path).convert('RGB')\n",
    "#     object, prompt = row['correct_obj'], row['correct_obj+context']\n",
    "#     print(f\"Processing {img_name} with object: {object} and prompt: {prompt}\")\n",
    "\n",
    "#     mod_prompt = utils.perform_word_swaps(prompt, {object: '_', object + 's': '_'})\n",
    "#     word_swap = word_swaps.get(object, object)\n",
    "#     swap_prompt = utils.perform_word_swaps(prompt, word_swaps)\n",
    "\n",
    "#     # Encode image to SD latent space\n",
    "#     x_real_transformed = sdm.sdm_pipe.image_processor.preprocess(img, height=512, width=512).squeeze().permute((1, 2, 0))\n",
    "#     x_real = sdm.encode_latents(img)\n",
    "\n",
    "#     # Encode prompts to CLIP embedding space\n",
    "#     v_org = sdm.encode_prompts(prompt).expand(batch_size, -1, -1)\n",
    "#     v_null = sdm.encode_prompts('').expand(batch_size, -1, -1)\n",
    "#     v_obj = sdm.encode_prompts(object).expand(batch_size, -1, -1)\n",
    "#     v_mod = sdm.encode_prompts(mod_prompt).expand(batch_size, -1, -1)\n",
    "#     v_swap = sdm.encode_prompts(swap_prompt).expand(batch_size, -1, -1)\n",
    "\n",
    "#     # Run in reverse to get the latent\n",
    "#     latent_real = utils.reverse(sdm, step_function, schedule_reversible, x_real, prompt)\n",
    "    \n",
    "#     ######################################################\n",
    "#     ##                   No intervention                ##\n",
    "#     ######################################################\n",
    "#     # Then run forward (no intervention) and check recovery of real image - also track attention\n",
    "#     with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "#         with trace(sdm.sdm_pipe) as tc:\n",
    "#             recover_real = utils.generate(sdm, step_function, schedule_reversible, latent_real, prompt)\n",
    "\n",
    "#     # Recover heat map\n",
    "#     heat_map = tc.compute_global_heat_map(prompt)\n",
    "#     heat_map = heat_map.compute_word_heat_map(object)  # keyword\n",
    "#     heat_map_lr = heat_map.value\n",
    "#     heat_map = F.interpolate(heat_map.value.unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "#     # Decode real image without intervention\n",
    "#     recover_real_decode = sdm.decode_latents(recover_real)[0]\n",
    "\n",
    "#     ######################################################\n",
    "#     ##              Omit & Swap intervention            ##\n",
    "#     ######################################################\n",
    "#     # Then run with a change in the prompt\n",
    "#     recover_mod = utils.generate(sdm, step_function, schedule_reversible, latent_real, mod_prompt)\n",
    "#     recover_mod_decode = sdm.decode_latents(recover_mod)[0]\n",
    "\n",
    "#     # Same, but swap a word instead\n",
    "#     recover_swap = utils.generate(sdm, step_function, schedule_reversible, latent_real, swap_prompt)\n",
    "#     recover_swap_decode = sdm.decode_latents(recover_swap)[0]\n",
    "\n",
    "#     # Get Info heat maps\n",
    "#     with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "#         results_dict = itd.ll_ratio(x_real, v_null, v_obj, n_points=20,\n",
    "#                                     n_samples_per_point=n_samples_per_point,\n",
    "#                                     batch_size=batch_size, dim=(1,))\n",
    "#     mi_pixel_lr = results_dict['ll_ratio_pixel_app']\n",
    "#     mi_pixel = F.interpolate(results_dict['ll_ratio_pixel_app'].unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "#     mi = results_dict['ll_ratio_pixel'].sum()\n",
    "\n",
    "#     with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "#         results_dict = itd.ll_ratio(x_real, v_mod, v_org, n_points=20,\n",
    "#                                     n_samples_per_point=n_samples_per_point,\n",
    "#                                     batch_size=batch_size, dim=(1,))\n",
    "#     cmi_pixel_lr = results_dict['ll_ratio_pixel_app']\n",
    "#     cmi_pixel = F.interpolate(results_dict['ll_ratio_pixel_app'].unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "#     cmi = results_dict['ll_ratio_pixel'].sum()\n",
    "\n",
    "#     with t.cuda.amp.autocast(dtype=t.float16), t.no_grad():\n",
    "#         results_dict = itd.ll_ratio(x_real, v_swap, v_org, n_points=20,\n",
    "#                                     n_samples_per_point=n_samples_per_point,\n",
    "#                                     batch_size=batch_size, dim=(1,))\n",
    "#     cmi_pixel_swap_lr = results_dict['ll_ratio_pixel_app']\n",
    "#     cmi_pixel_swap = F.interpolate(results_dict['ll_ratio_pixel_app'].unsqueeze(0).unsqueeze(0), size=(512, 512), mode='bilinear').squeeze(0).squeeze(0)\n",
    "#     cmi_swap = results_dict['ll_ratio_pixel'].sum()\n",
    "\n",
    "#     data_to_save = {\n",
    "#         'mod_prompt': mod_prompt,\n",
    "#         'object': object,\n",
    "#         'word_swap': word_swap,\n",
    "#         'x_real_transformed': x_real_transformed,\n",
    "#         'recover_real_decode': recover_real_decode,\n",
    "#         'recover_mod_decode': recover_mod_decode,\n",
    "#         'recover_swap_decode': recover_swap_decode,\n",
    "#         'recover_mod': recover_mod,\n",
    "#         'recover_swap': recover_swap,\n",
    "#         'recover_real': recover_real,\n",
    "#         'cmi_pixel': cmi_pixel,\n",
    "#         'cmi_pixel_swap': cmi_pixel_swap,\n",
    "#         'mi_pixel': mi_pixel,\n",
    "#         'cmi_pixel_lr': cmi_pixel_lr,\n",
    "#         'cmi_pixel_swap_lr': cmi_pixel_swap_lr,\n",
    "#         'mi_pixel_lr': mi_pixel_lr,\n",
    "#         'heat_map_lr': heat_map_lr,\n",
    "#         'heat_map': heat_map,\n",
    "#         'cmi': cmi,\n",
    "#         'cmi_swap': cmi_swap,\n",
    "#         'mi': mi\n",
    "#     }\n",
    "\n",
    "#     # Save the dictionary to a file\n",
    "#     if not os.path.exists(res_out_dir):\n",
    "#         os.makedirs(res_out_dir)\n",
    "#     t.save(data_to_save, os.path.join(res_out_dir, img_name[:-4] + '.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infodp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
